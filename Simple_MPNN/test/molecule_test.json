1. Model Summary
Model(
  (lifting): Linear(in_features=119, out_features=300, bias=True)
  (mp1): MPLayer(
    (f1): Linear(in_features=300, out_features=300, bias=True)
    (f2): Linear(in_features=300, out_features=300, bias=True)
  )
  (mp2): MPLayer(
    (f1): Linear(in_features=300, out_features=300, bias=True)
    (f2): Linear(in_features=300, out_features=300, bias=True)
  )
  (mp3): MPLayer(
    (f1): Linear(in_features=300, out_features=300, bias=True)
    (f2): Linear(in_features=300, out_features=300, bias=True)
  )
  (read_out): Linear(in_features=300, out_features=2, bias=True)
)

2. Test data structure of one molecule: nodes, edges and label
 one molecule example
 num nodes = 23 (number of atoms)
 num egdes = 25 (bonds of atoms)
 nodes = [ [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
            0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]

 edges = [(12, 0), (0, 24), (16, 1), (1, 27), (2, 24), (33, 3), (3, 38), (36, 4),
          (5, 38), (6, 43), (7, 24), (8, 40), (8, 43), (9, 10), (9, 11), (9, 14),
          (10, 12), (10, 15), (11, 13), (11, 18), (11, 20), (12, 19), (13, 17),
          (13, 21), (14, 16), (15, 17), (16, 19), (18, 22), (21, 23), (22, 25),
          (23, 26), (23, 28), (25, 29), (25, 31), (26, 30), (29, 34), (30, 32),
          (32, 33), (32, 39), (33, 35), (34, 37), (35, 36), (35, 41), (36, 40),
          (37, 38), (40, 42), (43, 44)]

 label = 0

-------------------------------------------------------------------------------
3.
C:\ProgramData\Anaconda3\python.exe C:/AI/MPNN/MPNN_toy_model/mpnn.py
Using backend: pytorch
Starting at 2021-07-09 15:55:55.060881
C:\ProgramData\Anaconda3\lib\site-packages\dgl\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  return warnings.warn(message, category=category, stacklevel=1)
Epoch 0 at 2021-07-09 15:55:55.618409
training end at 2021-07-09 15:56:27.915152: takes = 0:00:32.296743
Test Accuracy = 65.14 %
Epoch 1 at 2021-07-09 15:56:30.177154
training end at 2021-07-09 15:57:01.236207: takes = 0:00:31.059053
Test Accuracy = 67.14 %
Epoch 2 at 2021-07-09 15:57:03.554542
training end at 2021-07-09 15:57:34.700779: takes = 0:00:31.146237
Test Accuracy = 68.29 %
Epoch 3 at 2021-07-09 15:57:36.912886
training end at 2021-07-09 15:58:08.659526: takes = 0:00:31.746640
Test Accuracy = 68.00 %
Epoch 4 at 2021-07-09 15:58:10.877617
training end at 2021-07-09 15:58:42.800379: takes = 0:00:31.922762
Test Accuracy = 68.29 %
Epoch 5 at 2021-07-09 15:58:45.001530
training end at 2021-07-09 15:59:16.818638: takes = 0:00:31.817108
Test Accuracy = 68.57 %
Epoch 6 at 2021-07-09 15:59:19.086596
training end at 2021-07-09 15:59:51.034693: takes = 0:00:31.948097
Test Accuracy = 68.00 %
Epoch 7 at 2021-07-09 15:59:53.223862
training end at 2021-07-09 16:00:25.127083: takes = 0:00:31.903221
Test Accuracy = 68.29 %
Epoch 8 at 2021-07-09 16:00:27.318775
training end at 2021-07-09 16:00:58.988591: takes = 0:00:31.669816
Test Accuracy = 68.29 %
Epoch 9 at 2021-07-09 16:01:01.143421
training end at 2021-07-09 16:01:32.945788: takes = 0:00:31.802367
Test Accuracy = 71.43 %
Epoch 10 at 2021-07-09 16:01:35.109519
training end at 2021-07-09 16:02:06.897517: takes = 0:00:31.787998
Test Accuracy = 71.43 %
Epoch 11 at 2021-07-09 16:02:09.104686
training end at 2021-07-09 16:02:40.591914: takes = 0:00:31.487228
Test Accuracy = 69.71 %
Epoch 12 at 2021-07-09 16:02:42.764115
training end at 2021-07-09 16:03:14.854331: takes = 0:00:32.090216
Test Accuracy = 70.00 %
Epoch 13 at 2021-07-09 16:03:17.045507
training end at 2021-07-09 16:03:49.495199: takes = 0:00:32.449692
Test Accuracy = 71.71 %
Epoch 14 at 2021-07-09 16:03:51.655524
training end at 2021-07-09 16:04:23.676835: takes = 0:00:32.021311
Test Accuracy = 71.14 %
Epoch 15 at 2021-07-09 16:04:25.836069
training end at 2021-07-09 16:04:58.180691: takes = 0:00:32.344622
Test Accuracy = 70.86 %
Epoch 16 at 2021-07-09 16:05:00.352402
training end at 2021-07-09 16:05:32.620139: takes = 0:00:32.267737
Test Accuracy = 71.71 %
Epoch 17 at 2021-07-09 16:05:34.791385
training end at 2021-07-09 16:06:06.701040: takes = 0:00:31.909655
Test Accuracy = 72.00 %
Epoch 18 at 2021-07-09 16:06:08.970018
training end at 2021-07-09 16:06:40.659194: takes = 0:00:31.689176
Test Accuracy = 72.00 %
Epoch 19 at 2021-07-09 16:06:42.854376
training end at 2021-07-09 16:07:14.820766: takes = 0:00:31.966390
Test Accuracy = 71.43 %
Epoch 20 at 2021-07-09 16:07:16.973520
training end at 2021-07-09 16:07:48.618647: takes = 0:00:31.645127
Test Accuracy = 71.14 %
Epoch 21 at 2021-07-09 16:07:50.804313
training end at 2021-07-09 16:08:22.654936: takes = 0:00:31.850623
Test Accuracy = 70.86 %
Epoch 22 at 2021-07-09 16:08:24.825801
training end at 2021-07-09 16:08:56.786192: takes = 0:00:31.960391
Test Accuracy = 71.14 %
Epoch 23 at 2021-07-09 16:08:58.941455
training end at 2021-07-09 16:09:31.137722: takes = 0:00:32.196267
Test Accuracy = 72.57 %
Epoch 24 at 2021-07-09 16:09:33.311929
training end at 2021-07-09 16:10:05.102805: takes = 0:00:31.790876
Test Accuracy = 70.86 %
Epoch 25 at 2021-07-09 16:10:07.276504
training end at 2021-07-09 16:10:40.092075: takes = 0:00:32.815571
Test Accuracy = 72.57 %
Epoch 26 at 2021-07-09 16:10:42.350037
training end at 2021-07-09 16:11:14.372222: takes = 0:00:32.022185
Test Accuracy = 72.57 %
Epoch 27 at 2021-07-09 16:11:16.549401
training end at 2021-07-09 16:11:48.485529: takes = 0:00:31.936128
Test Accuracy = 73.71 %
Epoch 28 at 2021-07-09 16:11:50.640766
training end at 2021-07-09 16:12:22.344529: takes = 0:00:31.703763
Test Accuracy = 73.14 %
Epoch 29 at 2021-07-09 16:12:24.508768
training end at 2021-07-09 16:12:56.307082: takes = 0:00:31.798314
Test Accuracy = 71.43 %
Epoch 30 at 2021-07-09 16:12:58.507231
training end at 2021-07-09 16:13:30.752393: takes = 0:00:32.245162
Test Accuracy = 72.29 %
Epoch 31 at 2021-07-09 16:13:32.904643
training end at 2021-07-09 16:14:04.806221: takes = 0:00:31.901578
Test Accuracy = 73.71 %
Epoch 32 at 2021-07-09 16:14:06.973965
training end at 2021-07-09 16:14:39.019033: takes = 0:00:32.045068
Test Accuracy = 73.43 %
Epoch 33 at 2021-07-09 16:14:41.189235
training end at 2021-07-09 16:15:12.933573: takes = 0:00:31.744338
Test Accuracy = 72.29 %
Epoch 34 at 2021-07-09 16:15:15.109848
training end at 2021-07-09 16:15:46.816057: takes = 0:00:31.706209
Test Accuracy = 73.14 %
Epoch 35 at 2021-07-09 16:15:48.963367
training end at 2021-07-09 16:16:20.746872: takes = 0:00:31.783505
Test Accuracy = 74.00 %
Epoch 36 at 2021-07-09 16:16:23.012841
training end at 2021-07-09 16:16:57.761353: takes = 0:00:34.748512
Test Accuracy = 71.43 %
Epoch 37 at 2021-07-09 16:17:00.246757
training end at 2021-07-09 16:17:36.844610: takes = 0:00:36.597853
Test Accuracy = 75.14 %
Epoch 38 at 2021-07-09 16:17:39.089143
training end at 2021-07-09 16:18:12.750841: takes = 0:00:33.661698
Test Accuracy = 75.14 %
Epoch 39 at 2021-07-09 16:18:15.017857
training end at 2021-07-09 16:18:46.965844: takes = 0:00:31.947987
Test Accuracy = 75.14 %
Epoch 40 at 2021-07-09 16:18:49.109657
training end at 2021-07-09 16:19:20.863220: takes = 0:00:31.753563
Test Accuracy = 74.00 %
Epoch 41 at 2021-07-09 16:19:23.008503
training end at 2021-07-09 16:19:54.641641: takes = 0:00:31.633138
Test Accuracy = 74.00 %
Epoch 42 at 2021-07-09 16:19:56.776934
training end at 2021-07-09 16:20:28.512524: takes = 0:00:31.735590
Test Accuracy = 75.71 %
Epoch 43 at 2021-07-09 16:20:30.637379
training end at 2021-07-09 16:21:02.192724: takes = 0:00:31.555345
Test Accuracy = 75.14 %
Epoch 44 at 2021-07-09 16:21:04.351523
training end at 2021-07-09 16:21:35.749442: takes = 0:00:31.397919
Test Accuracy = 74.29 %
Epoch 45 at 2021-07-09 16:21:37.922175
training end at 2021-07-09 16:22:09.341624: takes = 0:00:31.419449
Test Accuracy = 72.57 %
Epoch 46 at 2021-07-09 16:22:11.476915
training end at 2021-07-09 16:22:43.038504: takes = 0:00:31.561589
Test Accuracy = 69.43 %
Epoch 47 at 2021-07-09 16:22:45.175325
training end at 2021-07-09 16:23:16.614616: takes = 0:00:31.439291
Test Accuracy = 72.57 %
Epoch 48 at 2021-07-09 16:23:18.747938
training end at 2021-07-09 16:23:50.655423: takes = 0:00:31.907485
Test Accuracy = 74.86 %
Epoch 49 at 2021-07-09 16:23:52.789225
training end at 2021-07-09 16:24:24.641338: takes = 0:00:31.852113
Test Accuracy = 73.43 %
Epoch 50 at 2021-07-09 16:24:26.771641
training end at 2021-07-09 16:24:58.132114: takes = 0:00:31.360473
Test Accuracy = 74.29 %
Epoch 51 at 2021-07-09 16:25:00.317776
training end at 2021-07-09 16:25:32.049393: takes = 0:00:31.731617
Test Accuracy = 74.86 %
Epoch 52 at 2021-07-09 16:25:34.176742
training end at 2021-07-09 16:26:05.780065: takes = 0:00:31.603323
Test Accuracy = 74.57 %
Epoch 53 at 2021-07-09 16:26:07.958748
training end at 2021-07-09 16:26:39.595856: takes = 0:00:31.637108
Test Accuracy = 76.29 %
Epoch 54 at 2021-07-09 16:26:41.748606
training end at 2021-07-09 16:27:13.772715: takes = 0:00:32.024109
Test Accuracy = 76.00 %
Epoch 55 at 2021-07-09 16:27:15.925956
training end at 2021-07-09 16:27:47.456995: takes = 0:00:31.531039
Test Accuracy = 74.00 %
Epoch 56 at 2021-07-09 16:27:49.596273
training end at 2021-07-09 16:28:21.173551: takes = 0:00:31.577278
Test Accuracy = 74.86 %
Epoch 57 at 2021-07-09 16:28:23.316371
training end at 2021-07-09 16:28:55.049632: takes = 0:00:31.733261
Test Accuracy = 73.14 %
Epoch 58 at 2021-07-09 16:28:57.156506
training end at 2021-07-09 16:29:28.613806: takes = 0:00:31.457300
Test Accuracy = 74.00 %
Epoch 59 at 2021-07-09 16:29:30.751089
training end at 2021-07-09 16:30:02.211734: takes = 0:00:31.460645
Test Accuracy = 73.43 %
Epoch 60 at 2021-07-09 16:30:04.396953
training end at 2021-07-09 16:30:35.882176: takes = 0:00:31.485223
Test Accuracy = 75.14 %
Epoch 61 at 2021-07-09 16:30:38.051373
training end at 2021-07-09 16:31:09.594327: takes = 0:00:31.542954
Test Accuracy = 74.00 %
Epoch 62 at 2021-07-09 16:31:11.847807
training end at 2021-07-09 16:31:43.303073: takes = 0:00:31.455266
Test Accuracy = 74.86 %
Epoch 63 at 2021-07-09 16:31:45.552057
training end at 2021-07-09 16:32:17.121991: takes = 0:00:31.569934
Test Accuracy = 78.57 %
Epoch 64 at 2021-07-09 16:32:19.280271
training end at 2021-07-09 16:32:50.885163: takes = 0:00:31.604892
Test Accuracy = 76.00 %
Epoch 65 at 2021-07-09 16:32:53.013526
training end at 2021-07-09 16:33:28.978227: takes = 0:00:35.964701
Test Accuracy = 76.00 %
Epoch 66 at 2021-07-09 16:33:31.233217
training end at 2021-07-09 16:34:03.890644: takes = 0:00:32.657427
Test Accuracy = 74.86 %
Epoch 67 at 2021-07-09 16:34:06.078792
training end at 2021-07-09 16:34:37.540991: takes = 0:00:31.462199
Test Accuracy = 75.14 %
Epoch 68 at 2021-07-09 16:34:39.677305
training end at 2021-07-09 16:35:10.999350: takes = 0:00:31.322045
Test Accuracy = 74.29 %
Epoch 69 at 2021-07-09 16:35:13.160569
training end at 2021-07-09 16:35:44.736011: takes = 0:00:31.575442
Test Accuracy = 74.57 %
Epoch 70 at 2021-07-09 16:35:46.890249
training end at 2021-07-09 16:36:18.466783: takes = 0:00:31.576534
Test Accuracy = 73.14 %
Epoch 71 at 2021-07-09 16:36:20.686844
training end at 2021-07-09 16:36:52.228703: takes = 0:00:31.541859
Test Accuracy = 75.43 %
Epoch 72 at 2021-07-09 16:36:54.402888
training end at 2021-07-09 16:37:25.970204: takes = 0:00:31.567316
Test Accuracy = 74.57 %
Epoch 73 at 2021-07-09 16:37:28.109075
training end at 2021-07-09 16:37:59.807484: takes = 0:00:31.698409
Test Accuracy = 73.14 %
Epoch 74 at 2021-07-09 16:38:01.913360
training end at 2021-07-09 16:38:33.398521: takes = 0:00:31.485161
Test Accuracy = 73.43 %
Epoch 75 at 2021-07-09 16:38:35.700364
training end at 2021-07-09 16:39:07.258720: takes = 0:00:31.558356
Test Accuracy = 77.71 %
Epoch 76 at 2021-07-09 16:39:09.471801
training end at 2021-07-09 16:39:41.019746: takes = 0:00:31.547945
Test Accuracy = 74.00 %
Epoch 77 at 2021-07-09 16:39:43.273229
training end at 2021-07-09 16:40:14.690443: takes = 0:00:31.417214
Test Accuracy = 75.43 %
Epoch 78 at 2021-07-09 16:40:16.838697
training end at 2021-07-09 16:40:48.253005: takes = 0:00:31.414308
Test Accuracy = 77.71 %
Epoch 79 at 2021-07-09 16:40:50.405778
training end at 2021-07-09 16:41:22.494353: takes = 0:00:32.088575
Test Accuracy = 75.14 %
Epoch 80 at 2021-07-09 16:41:24.640124
training end at 2021-07-09 16:41:56.323698: takes = 0:00:31.683574
Test Accuracy = 76.00 %
Epoch 81 at 2021-07-09 16:41:58.442537
training end at 2021-07-09 16:42:30.256712: takes = 0:00:31.814175
Test Accuracy = 74.57 %
Epoch 82 at 2021-07-09 16:42:32.389516
training end at 2021-07-09 16:43:03.988262: takes = 0:00:31.598746
Test Accuracy = 74.86 %
Epoch 83 at 2021-07-09 16:43:06.242257
training end at 2021-07-09 16:43:38.897306: takes = 0:00:32.655049
Test Accuracy = 76.86 %
Epoch 84 at 2021-07-09 16:43:41.055071
training end at 2021-07-09 16:44:12.880622: takes = 0:00:31.825551
Test Accuracy = 76.86 %
Epoch 85 at 2021-07-09 16:44:15.040869
training end at 2021-07-09 16:44:46.787849: takes = 0:00:31.746980
Test Accuracy = 75.71 %
Epoch 86 at 2021-07-09 16:44:48.939096
training end at 2021-07-09 16:45:20.315103: takes = 0:00:31.376007
Test Accuracy = 76.57 %
Epoch 87 at 2021-07-09 16:45:22.445406
training end at 2021-07-09 16:45:54.006291: takes = 0:00:31.560885
Test Accuracy = 75.43 %
Epoch 88 at 2021-07-09 16:45:56.175029
training end at 2021-07-09 16:46:27.816319: takes = 0:00:31.641290
Test Accuracy = 75.43 %
Epoch 89 at 2021-07-09 16:46:30.055378
training end at 2021-07-09 16:47:01.603402: takes = 0:00:31.548024
Test Accuracy = 76.00 %
Epoch 90 at 2021-07-09 16:47:03.770621
training end at 2021-07-09 16:47:35.243397: takes = 0:00:31.472776
Test Accuracy = 74.00 %
Epoch 91 at 2021-07-09 16:47:37.384241
training end at 2021-07-09 16:48:08.964728: takes = 0:00:31.580487
Test Accuracy = 74.57 %
Epoch 92 at 2021-07-09 16:48:11.151894
training end at 2021-07-09 16:48:42.881992: takes = 0:00:31.730098
Test Accuracy = 77.43 %
Epoch 93 at 2021-07-09 16:48:45.044826
training end at 2021-07-09 16:49:16.598490: takes = 0:00:31.553664
Test Accuracy = 77.43 %
Epoch 94 at 2021-07-09 16:49:18.806111
training end at 2021-07-09 16:49:50.675848: takes = 0:00:31.869737
Test Accuracy = 77.14 %
Epoch 95 at 2021-07-09 16:49:52.814171
training end at 2021-07-09 16:50:24.455504: takes = 0:00:31.641333
Test Accuracy = 74.57 %
Epoch 96 at 2021-07-09 16:50:26.601287
training end at 2021-07-09 16:50:58.027778: takes = 0:00:31.426491
Test Accuracy = 77.14 %
Epoch 97 at 2021-07-09 16:51:00.169089
training end at 2021-07-09 16:51:31.652416: takes = 0:00:31.483327
Test Accuracy = 75.43 %
Epoch 98 at 2021-07-09 16:51:33.778764
training end at 2021-07-09 16:52:05.370505: takes = 0:00:31.591741
Test Accuracy = 76.00 %
Epoch 99 at 2021-07-09 16:52:07.526300
training end at 2021-07-09 16:52:38.945202: takes = 0:00:31.418902
Test Accuracy = 77.43 %

Process finished with exit code 0
